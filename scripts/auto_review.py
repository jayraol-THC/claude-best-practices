#!/usr/bin/env python3
"""
Auto-review r/claude for new best practices using Gemini 3 Pro with Google Search.
"""

import os
import json
import re
from datetime import datetime
from pathlib import Path

import google.generativeai as genai

# Configuration
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")
BEST_PRACTICES_FILE = Path(__file__).parent.parent / "PARALLEL_CODING_BEST_PRACTICES.md"
OUTPUT_FILE = Path(__file__).parent.parent / "MONTHLY_UPDATE.md"

SEARCH_TOPICS = [
    "cost optimization Claude Code",
    "parallel agents Claude",
    "git worktree Claude Code",
    "CLAUDE.md configuration tips",
    "Claude agent teams orchestration",
    "Haiku Sonnet model routing cost",
    "Claude Code sub-agents",
    "Claude Code context management tokens",
]


def search_and_summarize() -> dict:
    """Use Gemini 3 Pro with Google Search to find and summarize r/claude insights."""

    genai.configure(api_key=GEMINI_API_KEY)

    model = genai.GenerativeModel(
        model_name="gemini-2.0-flash",  # Use latest available with search
        tools="google_search_retrieval",
    )

    # Build search prompt
    topics_list = "\n".join(f"- {topic}" for topic in SEARCH_TOPICS)
    current_date = datetime.now().strftime("%B %Y")

    prompt = f"""Search Reddit r/claude and r/claudeai for posts from the last 30 days about these topics:

{topics_list}

For each topic, find the most upvoted or discussed tips, techniques, and insights.

Return a structured JSON response with this exact format:
{{
    "search_date": "{current_date}",
    "findings": [
        {{
            "category": "Cost Optimization | Parallel Agents | Context Management | Configuration | Tools",
            "title": "Brief title of the tip/technique",
            "summary": "2-3 sentence summary of the insight",
            "source_hint": "r/claude or r/claudeai, approximate date if known",
            "actionable_tip": "One concrete action users can take"
        }}
    ],
    "new_tools_mentioned": [
        {{
            "name": "Tool name",
            "description": "What it does",
            "url": "GitHub or website URL if found"
        }}
    ],
    "pricing_changes": "Any mentions of Claude pricing changes, or 'None found'",
    "notable_threads": [
        "Brief description of any highly-discussed threads worth reading"
    ]
}}

Focus on practical, actionable insights. Ignore promotional content or basic questions.
If no recent posts found for a topic, skip it.
Return ONLY valid JSON, no markdown formatting.
"""

    response = model.generate_content(prompt)

    # Extract JSON from response
    response_text = response.text.strip()

    # Handle markdown code blocks if present
    if response_text.startswith("```"):
        response_text = re.sub(r"```json?\n?", "", response_text)
        response_text = re.sub(r"\n?```$", "", response_text)

    try:
        return json.loads(response_text)
    except json.JSONDecodeError:
        # Return raw text if JSON parsing fails
        return {"raw_response": response_text, "parse_error": True}


def generate_update_markdown(findings: dict) -> str:
    """Convert findings to markdown format for the update file."""

    date = findings.get("search_date", datetime.now().strftime("%B %Y"))

    md = f"""# Monthly r/claude Review - {date}

> Auto-generated by Gemini 3 Pro with Google Search grounding

---

## New Findings

"""

    if findings.get("parse_error"):
        md += f"### Raw Response (JSON parsing failed)\n\n{findings.get('raw_response', 'No response')}\n\n"
        return md

    # Group findings by category
    categories = {}
    for finding in findings.get("findings", []):
        cat = finding.get("category", "Other")
        if cat not in categories:
            categories[cat] = []
        categories[cat].append(finding)

    for category, items in categories.items():
        md += f"### {category}\n\n"
        for item in items:
            md += f"**{item.get('title', 'Untitled')}**\n\n"
            md += f"{item.get('summary', '')}\n\n"
            md += f"- **Source:** {item.get('source_hint', 'r/claude')}\n"
            md += f"- **Action:** {item.get('actionable_tip', 'N/A')}\n\n"
        md += "---\n\n"

    # New tools
    tools = findings.get("new_tools_mentioned", [])
    if tools:
        md += "## New Tools Mentioned\n\n"
        md += "| Tool | Description | Link |\n"
        md += "|------|-------------|------|\n"
        for tool in tools:
            name = tool.get("name", "Unknown")
            desc = tool.get("description", "")
            url = tool.get("url", "#")
            md += f"| **{name}** | {desc} | [Link]({url}) |\n"
        md += "\n---\n\n"

    # Pricing changes
    pricing = findings.get("pricing_changes", "None found")
    md += f"## Pricing Updates\n\n{pricing}\n\n---\n\n"

    # Notable threads
    threads = findings.get("notable_threads", [])
    if threads:
        md += "## Notable Threads Worth Reading\n\n"
        for thread in threads:
            md += f"- {thread}\n"
        md += "\n---\n\n"

    md += """## Next Steps

Review the findings above and:
1. Add valuable insights to `PARALLEL_CODING_BEST_PRACTICES.md`
2. Update cost ratios if pricing changed
3. Add new tools to the resources section
4. Remove any outdated information

---

*Generated automatically. Please review before merging.*
"""

    return md


def main():
    if not GEMINI_API_KEY:
        print("Error: GEMINI_API_KEY environment variable not set")
        exit(1)

    print("Searching r/claude with Gemini 3 Pro...")
    findings = search_and_summarize()

    print("Generating update markdown...")
    update_md = generate_update_markdown(findings)

    print(f"Writing to {OUTPUT_FILE}...")
    OUTPUT_FILE.write_text(update_md)

    print("Done!")
    print(f"\nFindings summary:")
    print(f"- Categories found: {len(set(f.get('category', '') for f in findings.get('findings', [])))}")
    print(f"- Total insights: {len(findings.get('findings', []))}")
    print(f"- New tools: {len(findings.get('new_tools_mentioned', []))}")


if __name__ == "__main__":
    main()
